---

# Role - Main Tasks

- name: "Kubernetes | Debian/Ubuntu | Configure repo and install packages"
  when:
    - k8s_manage_repos
    - ansible_os_family == 'Debian'
  become: true
  block:
    - name: "Install gnupg for key dearmor"
      ansible.builtin.apt:
        name: gnupg
        state: present
        update_cache: true

    - name: "Ensure apt keyrings directory exists"
      ansible.builtin.file:
        path: /etc/apt/keyrings
        state: directory
        mode: "0755"

    - name: "Download Kubernetes Release.key"
      ansible.builtin.get_url:
        url: "https://pkgs.k8s.io/core:/stable:/{{ k8s_version_channel }}/deb/Release.key"
        dest: "/etc/apt/keyrings/kubernetes-apt-keyring.asc"
        mode: "0644"
        force: true

    - name: "Dearmor Kubernetes apt key"
      ansible.builtin.command: >-
        gpg --dearmor -o {{ k8s_apt_key_dest }} /etc/apt/keyrings/kubernetes-apt-keyring.asc
      args:
        creates: "{{ k8s_apt_key_dest }}"

    - name: "Ensure keyring file permissions"
      ansible.builtin.file:
        path: "{{ k8s_apt_key_dest }}"
        mode: "0644"
        state: file

    - name: "Add Kubernetes apt repository"
      ansible.builtin.apt_repository:
        repo: "deb [signed-by={{ k8s_apt_key_dest }}] https://pkgs.k8s.io/core:/stable:/{{ k8s_version_channel }}/deb/ /"
        filename: "{{ k8s_apt_repo_filename }}"
        state: present
        update_cache: true

    - name: "Install Kubernetes packages"
      ansible.builtin.apt:
        name: "{{ k8s_packages }}"
        state: present

- name: "Kubernetes | Fedora | Configure repo and install packages"
  when:
    - k8s_manage_repos
    - ansible_distribution == 'Fedora'
  block:
    - name: "Configure Kubernetes repo on Fedora"
      ansible.builtin.yum_repository:
        name: "{{ k8s_yum_repo_name }}"
        description: "Kubernetes"
        baseurl: "https://pkgs.k8s.io/core:/stable:/{{ k8s_version_channel }}/rpm/"
        enabled: true
        gpgcheck: true
        gpgkey: "https://pkgs.k8s.io/core:/stable:/{{ k8s_version_channel }}/rpm/repodata/repomd.xml.key"
        state: present

    - name: "Install Kubernetes packages on Fedora"
      ansible.builtin.dnf:
        name: "{{ k8s_packages }}"
        state: present
        disable_excludes: "{{ k8s_disable_excludes }}"

- name: "Kubernetes | RHEL/Fedora | Configure repo and install packages"
  when:
    - k8s_manage_repos
    - ansible_os_family in ['RedHat']
    - ansible_distribution != 'Fedora'
  block:
    - name: "Include pkg-management role for RHEL/Fedora"
      ansible.builtin.include_role:
        name: iamenr0s.ansible_role_pkg_management
      vars:
        pkg_yum_repositories:
          - name: "{{ k8s_yum_repo_name }}"
            description: "Kubernetes"
            baseurl: "https://pkgs.k8s.io/core:/stable:/{{ k8s_version_channel }}/rpm/"
            enabled: true
            gpgcheck: true
            gpgkey: "https://pkgs.k8s.io/core:/stable:/{{ k8s_version_channel }}/rpm/repodata/repomd.xml.key"
            state: present
        pkg_disable_excludes: "{{ k8s_disable_excludes }}"
        pkg_install: "{{ k8s_packages }}"

- name: "Kubernetes | Enable and start kubelet"
  when:
    - k8s_enable_kubelet
  ansible.builtin.systemd:
    name: kubelet
    enabled: true
    state: started

- name: "Kubernetes | Control Plane | Configure firewalld and SELinux"
  when:
    - inventory_hostname in groups[k8s_control_plane_group] | default([])
  ansible.builtin.include_role:
    name: iamenr0s.ansible_role_firewalld
  vars:
    firewalld_manage_kernel: false
    firewalld_manage_selinux: true
    firewalld_selinux_state: permissive
    firewalld_selinux_policy: targeted
    firewalld_zones_present:
      - public
    firewalld_ports:
      - { port: "6443/tcp", zone: "public" }
      - { port: "2379/tcp", zone: "public" }
      - { port: "2380/tcp", zone: "public" }
      - { port: "10250/tcp", zone: "public" }
      - { port: "10251/tcp", zone: "public" }
      - { port: "10252/tcp", zone: "public" }
      - { port: "10257/tcp", zone: "public" }
      - { port: "10259/tcp", zone: "public" }
      - { port: "179/tcp", zone: "public" }
      - { port: "4789/udp", zone: "public" }

- name: "Kubernetes | Workers | Configure firewalld and SELinux"
  when:
    - inventory_hostname in groups[k8s_workers_group] | default([])
  ansible.builtin.include_role:
    name: iamenr0s.ansible_role_firewalld
  vars:
    firewalld_manage_kernel: false
    firewalld_manage_selinux: true
    firewalld_selinux_state: permissive
    firewalld_selinux_policy: targeted
    firewalld_zones_present:
      - public
    firewalld_ports:
      - { port: "179/tcp", zone: "public" }
      - { port: "10250/tcp", zone: "public" }
      - { port: "30000-32767/tcp", zone: "public" }
      - { port: "4789/udp", zone: "public" }

- name: "Kubernetes | Control Plane | Initialize cluster with kubeadm"
  when:
    - inventory_hostname in groups[k8s_control_plane_group] | default([])
  block:
    - name: "Set pod CIDR for Flannel if requested"
      when:
        - k8s_install_flannel
        - not k8s_use_pod_cidr
      ansible.builtin.set_fact:
        k8s_use_pod_cidr: true

    - name: "Check if cluster already initialized"
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: k8s_admin_conf

    - name: "Run kubeadm init"
      ansible.builtin.command: >-
        kubeadm init
        {% if k8s_use_pod_cidr %} --pod-network-cidr={{ k8s_pod_network_cidr }}{% endif %}
        {{ k8s_init_extra_args | default('') }}
      when: not k8s_admin_conf.stat.exists
      register: kubeadm_init_result
      changed_when: kubeadm_init_result.rc == 0

    - name: "Setup kubeconfig for root"
      when:
        - k8s_kubeconfig_setup
        - (k8s_admin_conf.stat.exists or (kubeadm_init_result is defined and kubeadm_init_result.rc == 0))
      block:
        - name: "Ensure .kube directory exists"
          ansible.builtin.file:
            path: /root/.kube
            state: directory
            mode: '0750'

        - name: "Copy admin.conf to root kubeconfig"
          ansible.builtin.copy:
            src: /etc/kubernetes/admin.conf
            dest: /root/.kube/config
            owner: root
            group: root
            mode: '0640'
            remote_src: true

    - name: "Get kubeadm join command"
      ansible.builtin.command: kubeadm token create --print-join-command
      register: k8s_join_cmd_output
      changed_when: false

    - name: "Expose join command as host fact"
      ansible.builtin.set_fact:
        k8s_join_command: "{{ k8s_join_cmd_output.stdout }} {{ k8s_join_extra_args | default('') }}"

    - name: "Check if Flannel is installed"
      ansible.builtin.command: >-
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n {{ k8s_flannel_namespace }} get ds {{ k8s_flannel_ds_name }}
      register: k8s_flannel_get_ds
      failed_when: false
      changed_when: false

    - name: "Install Flannel CNI"
      when:
        - k8s_install_flannel
        - k8s_flannel_get_ds.rc != 0
      ansible.builtin.command: >-
        kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f {{ k8s_flannel_manifest_url }}
      register: k8s_flannel_apply
      changed_when: k8s_flannel_apply.rc == 0

- name: "Kubernetes | Workers | Join cluster"
  when:
    - inventory_hostname in groups[k8s_workers_group] | default([])
  block:
    - name: "Check if node already joined"
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
      register: k8s_kubelet_conf

    - name: "Join node to cluster"
      when:
        - not k8s_kubelet_conf.stat.exists
      ansible.builtin.command: >-
        {{ hostvars[groups[k8s_control_plane_group][0]].k8s_join_command }}
      register: kubeadm_join_result
      changed_when: kubeadm_join_result.rc == 0
